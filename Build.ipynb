{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Build.ipynb","provenance":[],"mount_file_id":"1TpBYd5QSqhVyprPH9N70ihKJ7BKP0JMw","authorship_tag":"ABX9TyOo3DaF59q9GbWBxVnb6MhP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"52v3dLujSNu7","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594930456465,"user_tz":240,"elapsed":346,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"73e7f22c-efa1-435c-fec6-894c3fc47ed0"},"source":["from google.colab import drive\n"," \n","# the project's folder\n","%cd /content/drive/My Drive/object_detection/data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/object_detection/data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"khia_Zz5Umhm"},"source":["!mkdir test_labels train_labels\n","!ls annotations/* | sort -R | head -100 | xargs -I{} mv {} test_labels/\n","!ls annotations/* | xargs -I{} mv {} train_labels/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"klgx9V1fXFIi"},"source":["!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVDv65KjXXtM"},"source":["!pip install tensorflow==1.15.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-EdE-87XXUGg"},"source":["from __future__ import division, print_function, absolute_import\n","\n","import pandas as pd\n","import numpy as np\n","import csv\n","\n","import re\n","import os\n","import io\n","import glob\n","import shutil\n","import urllib.request\n","import tarfile\n","import xml.etree.ElementTree as ET\n","\n","import tensorflow.compat.v1 as tf\n","import cv2 \n","\n","from PIL import Image\n","from collections import namedtuple, OrderedDict\n","\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u2SKNKH8bHrr","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594930473723,"user_tz":240,"elapsed":284,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"5ba64317-7379-41f3-a61c-a9483e8c2b5c"},"source":["print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eJA81zC4baI5","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594930959625,"user_tz":240,"elapsed":288,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"37f063ac-4aa7-4e04-dd58-832dcfae5df7"},"source":["%cd /content/drive/My Drive/object_detection/data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/object_detection/data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FZ9i7KC-bJsN","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594930961148,"user_tz":240,"elapsed":916,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"2f44188f-a6e5-49bc-e709-93229acd316d"},"source":["def xml_to_csv(path):\n","  classes_names = []\n","  xml_list = []\n","\n","  for xml_file in glob.glob(path + '/*.xml'):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    for member in root.findall('object'):\n","      classes_names.append(member[0].text)\n","      value = (root.find('filename').text,\n","               int(root.find('size')[0].text),\n","               int(root.find('size')[1].text),\n","               member[0].text,\n","               int(member[4][0].text),\n","               int(member[4][1].text),\n","               int(member[4][2].text),\n","               int(member[4][3].text))\n","      xml_list.append(value)\n","  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","  xml_df = pd.DataFrame(xml_list, columns=column_name) \n","  classes_names = list(set(classes_names))\n","  classes_names.sort()\n","  return xml_df, classes_names\n","\n","for label_path in ['train_labels', 'test_labels']:\n","  image_path = os.path.join(os.getcwd(), label_path)\n","  xml_df, classes = xml_to_csv(label_path)\n","  xml_df.to_csv(f'{label_path}.csv', index=None)\n","  print(f'Successfully converted {label_path} xml to csv.')\n","\n","label_map_path = os.path.join(\"label_map.pbtxt\")\n","pbtxt_content = \"\"\n","\n","for i, class_name in enumerate(classes):\n","    pbtxt_content = (\n","        pbtxt_content\n","        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n","    )\n","pbtxt_content = pbtxt_content.strip()\n","with open(label_map_path, \"w\") as f:\n","    f.write(pbtxt_content)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Successfully converted train_labels xml to csv.\n","Successfully converted test_labels xml to csv.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NeMsJ_jycZfq","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594930970077,"user_tz":240,"elapsed":297,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"8912f128-b024-446a-ab6b-aa2022e34c57"},"source":["%cd /content/drive/My Drive/object_detection"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X2xlz7jNb5di","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594930971919,"user_tz":240,"elapsed":1241,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"853da61a-7b8f-4b10-a75c-71acea532b6f"},"source":["!git clone --q https://github.com/tensorflow/models.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'models' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"29xYDtqodoEX","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594930973310,"user_tz":240,"elapsed":303,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"71cff6fe-0d78-4e2c-d0a8-07174f9b2b34"},"source":["%cd /content/drive/My Drive/object_detection/models/research/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/object_detection/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7_uuWpylcPDB","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594930975215,"user_tz":240,"elapsed":988,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"8772a43a-8543-4914-d020-35e234b844ba"},"source":["# compils the proto buffers\n","!protoc object_detection/protos/*.proto --python_out=.\n","# exports PYTHONPATH environment var with research and slim paths\n","os.environ['PYTHONPATH'] += ':./:./slim/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FpITxY_8egr4","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1594930979516,"user_tz":240,"elapsed":2761,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"6b237da8-dba0-4aea-9189-342198931746"},"source":["!pip install tf_slim"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tf_slim in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p8lFknGXddtR"},"source":["!python3 object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cS7yriWDhTwL","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1594931345803,"user_tz":240,"elapsed":208625,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"3377433f-d584-4a4e-9e6b-05f8e9354cd5"},"source":["from object_detection.utils import dataset_util\n","\n","data_base_url = '/content/drive/My Drive/object_detection/data/'\n","\n","image_dir = data_base_url + 'images/'\n","\n","def class_text_to_int(row_label):\n","  if row_label == 'skin' or row_label == 'referee' or row_label == 'wrestler' or row_label == 'wrestlers' or row_label == 'referees':\n","    return 1\n","  else:\n","    None\n","\n","def split(df, group):\n","  data = namedtuple('data',['filename','object'])\n","  gb = df.groupby(group)\n","  return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","def create_tf_example(group, path):\n","  with tf.io.gfile.GFile(os.path.join(path,'{}'.format(group.filename)), 'rb') as fid:\n","    encoded_jpg = fid.read()\n","  encoded_jpg_io = io.BytesIO(encoded_jpg)\n","  image = Image.open(encoded_jpg_io)\n","  width, height = image.size\n","  filename = group.filename.encode('utf8')\n","  image_format = b'jpg'\n","  xmins = []\n","  xmaxs = []\n","  ymins = []\n","  ymaxs = []\n","  classes_text = []\n","  classes = []\n","\n","  for index, row in group.object.iterrows():\n","    xmins.append(row['xmin'] / width)\n","    xmaxs.append(row['xmax'] / width)\n","    ymins.append(row['ymin'] / height)\n","    ymaxs.append(row['ymax'] / height)\n","    classes_text.append(row['class'].encode('utf8'))\n","    classes.append(class_text_to_int(row['class']))\n","\n","  tf_example = tf.train.Example(features=tf.train.Features(feature={\n","        'image/height': dataset_util.int64_feature(height),\n","        'image/width': dataset_util.int64_feature(width),\n","        'image/filename': dataset_util.bytes_feature(filename),\n","        'image/source_id': dataset_util.bytes_feature(filename),\n","        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","        'image/format': dataset_util.bytes_feature(image_format),\n","        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","        'image/object/bbox/ymin': dataset_util.float_list_feature(ymaxs),\n","        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","        'image/object/class/label': dataset_util.int64_list_feature(classes),\n","        }))\n","  return tf_example\n","\n","for csv in['train_labels', 'test_labels']:\n","  writer = tf.io.TFRecordWriter(data_base_url + csv + '.record')\n","  path = os.path.join(image_dir)\n","  examples = pd.read_csv(data_base_url + csv + '.csv')\n","  grouped = split(examples, 'filename')\n","  for group in grouped:\n","    tf_example = create_tf_example(group, path)\n","    writer.write(tf_example.SerializeToString())\n","\n","  writer.close()\n","  output_path = os.path.join(os.getcwd(), data_base_url + csv + '.record')\n","  print('Successfully created the TFRecords: {}'.format(data_base_url +csv + '.record'))\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Successfully created the TFRecords: /content/drive/My Drive/object_detection/data/train_labels.record\n","Successfully created the TFRecords: /content/drive/My Drive/object_detection/data/test_labels.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0XifknQcKht_"},"source":["MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","    },\n","}\n","\n","\n","selected_model = 'ssd_mobilenet_v2'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iR7krhradT7l","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594931539998,"user_tz":240,"elapsed":324,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"9f41e20f-04da-4897-f37e-95a00da270d7"},"source":["%cd /content/drive/My Drive/object_detection/models/research/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/object_detection/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLTycGq_da7g"},"source":["#the distination folder where the model will be saved\n","#change this if you have a different working dir\n","DEST_DIR = '/content/drive/My Drive/object_detection/models/research/pretrained_model'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","#selecting the model\n","MODEL_FILE = MODEL + '.tar.gz'\n","\n","#creating the downlaod link for the model selected\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","\n","#checks if the model has already been downloaded, download it otherwise\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","#unzipping the model and extracting its content\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","# creating an output file to save the model while training\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oiwOd0mMgDkE"},"source":["!cat object_detection/samples/configs/ssd_mobilenet_v2_coco.config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NwITe_i_hssM","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594931817432,"user_tz":240,"elapsed":335,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"70fd1d38-d290-4436-9216-6a776c3deaf8"},"source":["#path to the config file\n","%%writefile object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n","\n","# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  ssd {\n","    num_classes: 5\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000\n","        iou_threshold: 0.99\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 24\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.004\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","  fine_tune_checkpoint: \"/content/drive/My Drive/object_detection/models/research/pretrained_model/model.ckpt\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 200000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/My Drive/object_detection/data/train_labels.record\"\n","  }\n","  label_map_path: \"/content/drive/My Drive/object_detection/data/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 100\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  max_evals: 20\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/My Drive/object_detection/data/test_labels.record\"\n","  }\n","  label_map_path: \"/content/drive/My Drive/object_detection/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aCiMt4S6jP2x","colab":{"base_uri":"https://localhost:8080/","height":258},"executionInfo":{"status":"ok","timestamp":1594932478976,"user_tz":240,"elapsed":4099,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"fcb5b43a-7ea7-466d-a71a-f7c1e2b251d9"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-07-16 20:47:55--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.192.84.136, 54.159.115.94, 34.206.168.28, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.192.84.136|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  16.0MB/s    in 0.8s    \n","\n","2020-07-16 20:47:56 (16.0 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uVU6qciAjXlG","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594932516162,"user_tz":240,"elapsed":1902,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"a308818d-883f-4e6e-d900-743a53b43438"},"source":["#the logs that are created while training \n","LOG_DIR = \"training/\"\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","get_ipython().system_raw('./ngrok http 6006 &')\n","#The link to tensorboard.\n","#works after the training starts.\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["https://9667b77b5f56.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i1eDiJWK9_ys","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594932807063,"user_tz":240,"elapsed":545,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"5100e84c-e6f4-47fe-bf56-076188a6b4da"},"source":["%cd /content/drive/My Drive/object_detection/models/research/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/object_detection/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NJsUhZxs12MC","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594933147431,"user_tz":240,"elapsed":19547,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"ea9933dc-3037-48a4-c159-7f2c4a6b1b0f"},"source":["!python3 object_detection/model_main.py \\\n","    --pipeline_config_path=/content/drive/My\\ Drive/object_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config  \\\n","    --model_dir=training/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0716 20:58:51.610212 139714913130368 model_lib.py:758] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0716 20:58:51.610437 139714913130368 config_util.py:552] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0716 20:58:51.610586 139714913130368 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0716 20:58:51.610669 139714913130368 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0716 20:58:51.610749 139714913130368 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0716 20:58:51.610857 139714913130368 model_lib.py:774] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","I0716 20:58:51.610951 139714913130368 model_lib.py:809] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f11710254a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0716 20:58:51.611360 139714913130368 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f11710254a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1171020e18>) includes params argument, but params are not passed to Estimator.\n","W0716 20:58:51.612205 139714913130368 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1171020e18>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0716 20:58:51.613011 139714913130368 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0716 20:58:51.613183 139714913130368 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0716 20:58:51.613395 139714913130368 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0716 20:58:51.629173 139714913130368 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0716 20:58:51.667616 139714913130368 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/drive/My Drive/object_detection/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0716 20:58:51.672892 139714913130368 deprecation.py:323] From /content/drive/My Drive/object_detection/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/drive/My Drive/object_detection/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0716 20:58:51.693486 139714913130368 deprecation.py:323] From /content/drive/My Drive/object_detection/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /content/drive/My Drive/object_detection/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0716 20:59:03.020200 139714913130368 deprecation.py:323] From /content/drive/My Drive/object_detection/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /content/drive/My Drive/object_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0716 20:59:03.131660 139714913130368 deprecation.py:323] From /content/drive/My Drive/object_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Traceback (most recent call last):\n","  File \"object_detection/model_main.py\", line 108, in <module>\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"object_detection/model_main.py\", line 104, in main\n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n","    return executor.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n","    return self.run_local()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n","    saving_listeners=saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1188, in _train_model_default\n","    input_fn, ModeKeys.TRAIN))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n","    self._call_input_fn(input_fn, mode))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1116, in _call_input_fn\n","    return input_fn(**kwargs)\n","  File \"/content/drive/My Drive/object_detection/models/research/object_detection/inputs.py\", line 694, in _train_input_fn\n","    params=params)\n","  File \"/content/drive/My Drive/object_detection/models/research/object_detection/inputs.py\", line 832, in train_input\n","    reduce_to_frame_fn=reduce_to_frame_fn)\n","  File \"/content/drive/My Drive/object_detection/models/research/object_detection/builders/dataset_builder.py\", line 196, in build\n","    batch_size, input_reader_config)\n","  File \"/content/drive/My Drive/object_detection/models/research/object_detection/builders/dataset_builder.py\", line 175, in dataset_map_fn\n","    fn_to_map, num_parallel_calls=num_parallel_calls)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 1950, in map_with_legacy_function\n","    use_legacy_function=True))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3472, in __init__\n","    use_legacy_function=use_legacy_function)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2689, in __init__\n","    self._function.add_to_graph(ops.get_default_graph())\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/function.py\", line 545, in add_to_graph\n","    self._create_definition_if_needed()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/function.py\", line 377, in _create_definition_if_needed\n","    self._create_definition_if_needed_impl()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/function.py\", line 408, in _create_definition_if_needed_impl\n","    capture_resource_var_by_value=self._capture_resource_var_by_value)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/function.py\", line 944, in func_graph_from_py_func\n","    outputs = func(*func_graph.inputs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2681, in wrapper_fn\n","    ret = _wrapper_helper(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2652, in _wrapper_helper\n","    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 234, in wrapper\n","    return converted_call(f, options, args, kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmpacr2pfl4.py\", line 26, in tf__transform_and_pad_input_data_fn\n","    tensor_dict = ag__.converted_call(pad_input_data_to_static_shapes, transform_and_pad_input_data_fn_scope.callopts, (), {'tensor_dict': ag__.converted_call(transform_data_fn, transform_and_pad_input_data_fn_scope.callopts, (tensor_dict,), None, transform_and_pad_input_data_fn_scope), 'max_num_boxes': train_input_config.max_number_of_boxes, 'num_classes': num_classes, 'spatial_image_shape': ag__.converted_call(config_util.get_spatial_image_size, transform_and_pad_input_data_fn_scope.callopts, (image_resizer_config,), None, transform_and_pad_input_data_fn_scope), 'max_num_context_features': ag__.converted_call(config_util.get_max_num_context_features, transform_and_pad_input_data_fn_scope.callopts, (model_config,), None, transform_and_pad_input_data_fn_scope), 'context_feature_length': ag__.converted_call(config_util.get_context_feature_length, transform_and_pad_input_data_fn_scope.callopts, (model_config,), None, transform_and_pad_input_data_fn_scope)}, transform_and_pad_input_data_fn_scope)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmp97qeum8z.py\", line 214, in tf__transform_input_data\n","    out_tensor_dict = ag__.if_stmt(cond_8, if_true_8, if_false_8, get_state_8, set_state_8, ('out_tensor_dict',), ())\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\n","    return _py_if_stmt(cond, body, orelse)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\n","    return body() if cond else orelse()\n","  File \"/tmp/tmp97qeum8z.py\", line 208, in if_true_8\n","    out_tensor_dict_2 = ag__.converted_call(data_augmentation_fn, transform_input_data_scope.callopts, (out_tensor_dict_2,), None, transform_input_data_scope)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmp9kkrz43c.py\", line 35, in tf__augment_input_data\n","    tensor_dict = ag__.converted_call(preprocessor.preprocess, augment_input_data_scope.callopts, (tensor_dict, data_augmentation_options), {'func_arg_map': ag__.converted_call(preprocessor.get_default_func_arg_map, augment_input_data_scope.callopts, (), {'include_label_weights': include_label_weights, 'include_label_confidences': include_label_confidences, 'include_multiclass_scores': include_multiclass_scores, 'include_instance_masks': include_instance_masks, 'include_keypoints': include_keypoints, 'include_keypoint_visibilities': include_keypoint_visibilities, 'include_dense_pose': include_dense_pose}, augment_input_data_scope)}, augment_input_data_scope)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmphaqcy1jb.py\", line 239, in tf__preprocess\n","    ag__.for_stmt(preprocess_options, None, loop_body_2, get_state_11, set_state_11, (), (), ())\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 339, in for_stmt\n","    return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 350, in _py_for_stmt\n","    state = body(target, *state)\n","  File \"/tmp/tmphaqcy1jb.py\", line 208, in loop_body_2\n","    results = ag__.converted_call(func, preprocess_scope.callopts, () + tuple(args), dict(params, **{}), preprocess_scope)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmphk4lepa5.py\", line 120, in tf__random_horizontal_flip\n","    do_a_flip_random = ag__.converted_call(_get_or_create_preprocess_rand_vars, random_horizontal_flip_scope.callopts, (generator_func, preprocessor_cache.PreprocessorCache.HORIZONTAL_FLIP, preprocess_vars_cache), None, random_horizontal_flip_scope)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 541, in converted_call\n","    result = converted_f(*effective_args)\n","  File \"/tmp/tmp5kc7lmpd.py\", line 62, in tf___get_or_create_preprocess_rand_vars\n","    var = ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_1, set_state_1, ('var',), ())\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\n","    return _py_if_stmt(cond, body, orelse)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\n","    return body() if cond else orelse()\n","  File \"/tmp/tmp5kc7lmpd.py\", line 59, in if_false_1\n","    var = ag__.converted_call(generator_func, _get_or_create_preprocess_rand_vars_scope.callopts, (), None, _get_or_create_preprocess_rand_vars_scope)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 506, in converted_call\n","    converted_f = conversion.convert(target_entity, program_ctx)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 322, in convert\n","    free_nonglobal_var_names)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 240, in _convert_with_cache\n","    entity, program_ctx)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 469, in convert_entity_to_ast\n","    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 669, in convert_func_to_ast\n","    node = node_to_graph(node, context)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 702, in node_to_graph\n","    node = converter.apply_(node, context, break_statements)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/core/converter.py\", line 408, in apply_\n","    node = standard_analysis(node, context)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/core/converter.py\", line 384, in standard_analysis\n","    node = activity.resolve(node, context, None)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 498, in resolve\n","    return ActivityAnalyzer(context, parent_scope).visit(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n","    result = super(Base, self).visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 442, in visit_FunctionDef\n","    node.body = self.visit_block(node.body)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 371, in visit_block\n","    replacement = self.visit(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n","    result = super(Base, self).visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 451, in visit_With\n","    node = self.generic_visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 308, in generic_visit\n","    value = self.visit(value)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n","    result = super(Base, self).visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 461, in visit_If\n","    node.test = self.visit(node.test)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n","    result = super(Base, self).visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 308, in generic_visit\n","    value = self.visit(value)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n","    result = super(Base, self).visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 308, in generic_visit\n","    value = self.visit(value)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n","    result = super(Base, self).visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 301, in visit_Attribute\n","    node = self.generic_visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 317, in generic_visit\n","    new_node = self.visit(old_value)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n","    result = super(Base, self).visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 297, in visit_Name\n","    self._track_symbol(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 230, in _track_symbol\n","    self.scope.mark_read(qn)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 125, in mark_read\n","    self.parent.mark_read(name)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 124, in mark_read\n","    if self.parent is not None and name not in self.params:\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dR3f774zWjbP"},"source":["#dir where the model will be saved\n","output_directory = './fine_tuned_model'\n","\n","lst = os.listdir('training')\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join('training', last_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lVKJBxw7Wo6v"},"source":["\n","!python /content/drive/'My Drive'/object_detection/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path=/gdrive/My\\ Drive/object_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Ah2Ju3oYCC1","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1594932929568,"user_tz":240,"elapsed":526,"user":{"displayName":"Eric Schneider","photoUrl":"","userId":"15887512499218330457"}},"outputId":"8934802f-0a03-48d7-fbdc-6877e1014651"},"source":["#downlaod the label map\n","# we specified 'data_base_url' above. It directs to\n","# 'object_detection/data/' folder.\n","files.download(data_base_url + '/label_map.pbtxt')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_33201da2-d204-42e1-997c-41b3a6548390\", \"label_map.pbtxt\", 158)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"xdgmSrSjaXdk"},"source":["import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-oCwb3RavFV"},"source":[""],"execution_count":null,"outputs":[]}]}